defaults:
  - _self_

method: consistency_augmentation

train:
  total_epochs: 250
  validation_interval: 10

init:
  _target_: trainer.ConsistencyAugmentationTrainer
  supervised_criterion:
    _target_: torch.nn.MSELoss
  optimizer:
    _target_: torch.optim.AdamW
    _partial_: true
    lr: 0.001
    weight_decay: 0.005
  scheduler:
    _target_: torch.optim.lr_scheduler.StepLR
    _partial_: true
    step_size: 1
    gamma: 0.975
  
  # Consistency Hyperparameters
  consistency_weight: 1.0   # How much to weigh the augmentation loss
  ramp_up_epochs: 50        # Slowly increase weight to stabilize early training
  aug_noise_std: 0.1        # Jitter for 3D coordinates (important for SchNet/ViSNet)
  aug_mask_prob: 0.15       # Probability of zeroing out features (important for GCN)